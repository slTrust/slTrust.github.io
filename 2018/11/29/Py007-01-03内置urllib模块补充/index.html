
 <!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
  
    <title>Py007-01-03内置urllib模块补充 | Almost</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Stevin">
    

    
    <meta name="description" content="urllib补充1234567891011121314# 补充说明：urlopen函数原型：    urllib.request.urlopen(url, data=None, timeout=&amp;lt;object object at 0x10af327d0&amp;gt;, *, cafile=None, capath=None, cadefault=False, context=None)在上一节中我">
<meta name="keywords" content="M07">
<meta property="og:type" content="article">
<meta property="og:title" content="Py007-01-03内置urllib模块补充">
<meta property="og:url" content="http://yoursite.com/2018/11/29/Py007-01-03内置urllib模块补充/index.html">
<meta property="og:site_name" content="Almost">
<meta property="og:description" content="urllib补充1234567891011121314# 补充说明：urlopen函数原型：    urllib.request.urlopen(url, data=None, timeout=&amp;lt;object object at 0x10af327d0&amp;gt;, *, cafile=None, capath=None, cadefault=False, context=None)在上一节中我">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2020-09-08T12:50:20.299Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Py007-01-03内置urllib模块补充">
<meta name="twitter:description" content="urllib补充1234567891011121314# 补充说明：urlopen函数原型：    urllib.request.urlopen(url, data=None, timeout=&amp;lt;object object at 0x10af327d0&amp;gt;, *, cafile=None, capath=None, cadefault=False, context=None)在上一节中我">

    
    <link rel="alternative" href="/atom.xml" title="Almost" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>
</html>
  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Almost" title="Almost"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Almost">Almost</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:yoursite.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/11/29/Py007-01-03内置urllib模块补充/" title="Py007-01-03内置urllib模块补充" itemprop="url">Py007-01-03内置urllib模块补充</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Stevin" target="_blank" itemprop="author">Stevin</a>
		
  <p class="article-time">
    <time datetime="2018-11-29T14:59:14.000Z" itemprop="datePublished"> Published 2018-11-29</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">Contents</strong>
		
			<ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#urllib补充"><span class="toc-number">1.</span> <span class="toc-text">urllib补充</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#二进制数据的爬取"><span class="toc-number">1.1.</span> <span class="toc-text">二进制数据的爬取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#url的特性"><span class="toc-number">1.2.</span> <span class="toc-text">url的特性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#通过自定义请求对象，用于伪装爬虫程序请求的身份。"><span class="toc-number">1.3.</span> <span class="toc-text">通过自定义请求对象，用于伪装爬虫程序请求的身份。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#携带参数的post请求"><span class="toc-number">1.4.</span> <span class="toc-text">携带参数的post请求</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#urllib模块的高级操作"><span class="toc-number">2.</span> <span class="toc-text">urllib模块的高级操作</span></a></li></ol>
		
		</div>
		
		<h3 id="urllib补充"><a href="#urllib补充" class="headerlink" title="urllib补充"></a>urllib补充</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 补充说明：</span><br><span class="line">urlopen函数原型：</span><br><span class="line">    urllib.request.urlopen(url, data=None, timeout=&lt;object object at 0x10af327d0&gt;, *, cafile=None, capath=None, cadefault=False, context=None)</span><br><span class="line"></span><br><span class="line">在上一节中我们只使用了该函数中的第一个参数url。在日常开发中，我们能用的只有url和data这两个参数。</span><br><span class="line"></span><br><span class="line">url参数：指定向哪个url发起请求</span><br><span class="line">data参数：可以将post请求中携带的参数封装成字典的形式传递给该参数</span><br><span class="line"></span><br><span class="line">urlopen函数返回的响应对象，相关函数调用介绍：</span><br><span class="line">response.headers()：获取响应头信息</span><br><span class="line">response.getcode()：获取响应状态码</span><br><span class="line">response.geturl()：获取请求的url</span><br><span class="line">response.read()：获取响应中的数据值（字节类型）</span><br></pre></td></tr></table></figure>
<h4 id="二进制数据的爬取"><a href="#二进制数据的爬取" class="headerlink" title="二进制数据的爬取"></a>二进制数据的爬取</h4><blockquote>
<p>爬取网络上的某张图片数据，且存储到磁盘</p>
</blockquote>
<ul>
<li>方法 1：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line"></span><br><span class="line">#1.指定url</span><br><span class="line">url = &apos;https://pic.qiushibaike.com/system/pictures/12112/121121212/medium/ZOAND29U4NKNEWEF.jpg&apos;</span><br><span class="line">#2.发起请求:使用urlopen函数发起请求，该函数返回一个响应对象</span><br><span class="line">response = urllib.request.urlopen(url=url)</span><br><span class="line">#3.获取响应对象中的图片二进制类型的数据</span><br><span class="line">img_data = response.read()</span><br><span class="line">#4.持久化存储：将爬取的图片写入本地进行保存</span><br><span class="line">with open(&apos;./tupian.png&apos;,&apos;wb&apos;) as fp:</span><br><span class="line">    fp.write(img_data)</span><br></pre></td></tr></table></figure>
<ul>
<li>方法 2：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line"></span><br><span class="line">url = &apos;https://pic.qiushibaike.com/system/pictures/12112/121121212/medium/ZOAND29U4NKNEWEF.jpg&apos;</span><br><span class="line"># 函数原型：urllib.request.urlretrieve(url, filename=None)</span><br><span class="line"># 作用：对url发起请求，且将响应中的数据值写入磁盘进行存储</span><br><span class="line">urllib.request.urlretrieve(url=url,filename=&apos;./img.png&apos;)</span><br></pre></td></tr></table></figure>
<h4 id="url的特性"><a href="#url的特性" class="headerlink" title="url的特性"></a>url的特性</h4><p>url必须为ASCII编码的数据值。所以我们在爬虫代码中编写url时，如果url中存在非ASCII编码的数据值，则必须对其进行ASCII编码后，该url方可被使用。</p>
<blockquote>
<p>案例：爬取使用搜狗根据指定词条搜索到的页面数据（例如爬取词条为‘周杰伦’的页面数据）</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">url = &apos;https://www.sogou.com/web?query=周杰伦&apos;</span><br><span class="line">response = urllib.request.urlopen(url=url)</span><br><span class="line">data = response.read()</span><br><span class="line">with open(&apos;./周杰伦.html&apos;,&apos;wb&apos;) as fp:</span><br><span class="line">    fp.write(data)</span><br><span class="line">print(&apos;写入文件完毕&apos;)</span><br></pre></td></tr></table></figure>
<p>【注意】上述代码中url存在非ascii编码的数据，则该url无效。如果对其发起请求，则会报如下错误：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UnicodeEncodeError: &apos;ascii&apos; codec can&apos;t encode characters in position 15-17: ordinal not in range</span><br></pre></td></tr></table></figure>
<blockquote>
<p>所以必须对url中的非ascii的数据进行ascii的编码，则该url方可被发起请求：</p>
</blockquote>
<ul>
<li>方法 1：使用quote函数</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">url = &apos;https://www.sogou.com/web?query=%s&apos;</span><br><span class="line">#对url中的非ascii进行编码.quote函数可以对非ascii的数据值进行ascii的编码</span><br><span class="line">word = urllib.parse.quote(&apos;周杰伦&apos;)</span><br><span class="line">#将编码后的数据值拼接回url中</span><br><span class="line">url = format(url%word)</span><br><span class="line">response = urllib.request.urlopen(url=url)</span><br><span class="line">data = response.read()</span><br><span class="line">with open(&apos;./周杰伦.html&apos;,&apos;wb&apos;) as fp:</span><br><span class="line">    fp.write(data)</span><br><span class="line">print(&apos;写入文件完毕&apos;)</span><br></pre></td></tr></table></figure>
<ul>
<li>方法2： 使用urlencode函数</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">url = &apos;https://www.sogou.com/web?&apos;</span><br><span class="line">#将get请求中url携带的参数封装至字典中</span><br><span class="line">param = &#123;</span><br><span class="line">    &apos;query&apos;:&apos;周杰伦&apos;</span><br><span class="line">&#125;</span><br><span class="line">#对url中的非ascii进行编码</span><br><span class="line">param = urllib.parse.urlencode(param)</span><br><span class="line">#将编码后的数据值拼接回url中</span><br><span class="line">url += param </span><br><span class="line">response = urllib.request.urlopen(url=url)</span><br><span class="line">data = response.read()</span><br><span class="line">with open(&apos;./周杰伦1.html&apos;,&apos;wb&apos;) as fp:</span><br><span class="line">    fp.write(data)</span><br><span class="line">print(&apos;写入文件完毕&apos;)</span><br></pre></td></tr></table></figure>
<h4 id="通过自定义请求对象，用于伪装爬虫程序请求的身份。"><a href="#通过自定义请求对象，用于伪装爬虫程序请求的身份。" class="headerlink" title="通过自定义请求对象，用于伪装爬虫程序请求的身份。"></a>通过自定义请求对象，用于伪装爬虫程序请求的身份。</h4><p>之前在讲解http常用请求头信息时，我们讲解过User-Agent参数，简称为UA，该参数的作用是用于表明本次请求载体的身份标识。如果我们通过浏览器发起的请求，则该请求的载体为当前浏览器，则UA参数的值表明的是当前浏览器的身份标识表示的一串数据。如果我们使用爬虫程序发起的一个请求，则该请求的载体为爬虫程序，那么该请求的UA为爬虫程序的身份标识表示的一串数据。有些网站会通过辨别请求的UA来判别该请求的载体是否为爬虫程序，如果为爬虫程序，则不会给该请求返回响应，那么我们的爬虫程序则也无法通过请求爬取到该网站中的数据值，这也是反爬虫的一种初级技术手段。那么为了防止该问题的出现，则我们可以给爬虫程序的UA进行伪装，伪装成某款浏览器的身份标识。</p>
<p>上述案例中，我们是通过request模块中的urlopen发起的请求，该请求对象为urllib中内置的默认请求对象，我们无法对其进行UA进行更改操作。urllib还为我们提供了一种自定义请求对象的方式，我们可以通过自定义请求对象的方式，给该请求对象中的UA进行伪装（更改）操作。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">url = &apos;https://www.sogou.com/web?&apos;</span><br><span class="line">#将get请求中url携带的参数封装至字典中</span><br><span class="line">param = &#123;</span><br><span class="line">    &apos;query&apos;:&apos;周杰伦&apos;</span><br><span class="line">&#125;</span><br><span class="line">#对url中的非ascii进行编码</span><br><span class="line">param = urllib.parse.urlencode(param)</span><br><span class="line">#将编码后的数据值拼接回url中</span><br><span class="line">url += param </span><br><span class="line"></span><br><span class="line">#封装自定义的请求头信息的字典：</span><br><span class="line">#将浏览器的UA数据获取，封装到一个字典中。该UA值可以通过抓包工具或者浏览器自带的开发者工具中获取某请求，从中获取UA的值</span><br><span class="line">#注意：在headers字典中可以封装任意的请求头信息</span><br><span class="line">headers=&#123;</span><br><span class="line">    &apos;User-Agent&apos; : &apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36&apos;</span><br><span class="line">    &#125;</span><br><span class="line">#自定义请求对象，可以在该请求对象中添加自定义的请求头信息</span><br><span class="line">request = urllib.request.Request(url=url,headers=headers)</span><br><span class="line">#使用自定义请求对象发起请求</span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line">data = response.read()</span><br><span class="line">with open(&apos;./周杰伦.html&apos;,&apos;wb&apos;) as fp:</span><br><span class="line">    fp.write(data)</span><br><span class="line">print(&apos;写入文件完毕&apos;)</span><br></pre></td></tr></table></figure>
<h4 id="携带参数的post请求"><a href="#携带参数的post请求" class="headerlink" title="携带参数的post请求"></a>携带参数的post请求</h4><blockquote>
<p>案例：百度翻译发起post请求</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">#通过抓包工具抓取post请求的url</span><br><span class="line">post_url=&apos;https://fanyi.baidu.com/sug&apos;</span><br><span class="line">#封装post请求参数</span><br><span class="line">data=&#123;</span><br><span class="line">    &quot;kw&quot;:&quot;dog&quot;</span><br><span class="line">&#125;</span><br><span class="line">data=urllib.parse.urlencode(data)</span><br><span class="line">#自定义请求头信息字典</span><br><span class="line">headers=&#123;</span><br><span class="line">    &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#自定义请求对象，然后将封装好的post请求参数赋值给Requst方法的data参数。</span><br><span class="line">#data参数：用来存储post请求的参数</span><br><span class="line">request=urllib.request.Request(post_url,data=data.encode(),headers=headers)</span><br><span class="line">#自定义的请求对象中的参数（data必须为bytes类型）</span><br><span class="line">response=urllib.request.urlopen(request)</span><br><span class="line">response.read()</span><br></pre></td></tr></table></figure>
<h3 id="urllib模块的高级操作"><a href="#urllib模块的高级操作" class="headerlink" title="urllib模块的高级操作"></a>urllib模块的高级操作</h3><blockquote>
<ol>
<li>代理</li>
</ol>
</blockquote>
<ul>
<li><p>什么是代理：代理就是第三方代替本体处理相关事务。例如：生活中的代理：代购，中介，微商……</p>
</li>
<li><p>爬虫中为什么需要使用代理？</p>
<blockquote>
<p>一些网站会有相应的反爬虫措施，例如很多网站会检测某一段时间某个IP的访问次数，如果访问频率太快以至于看起来不像正常访客，它可能就会会禁止这个IP的访问。所以我们需要设置一些代理IP，每隔一段时间换一个代理IP，就算IP被禁止，依然可以换个IP继续爬取。</p>
</blockquote>
</li>
<li><p>代理的分类：</p>
</li>
</ul>
<p>正向代理：代理客户端获取数据。正向代理是为了保护客户端防止被追究责任。</p>
<p>反向代理：代理服务器提供数据。反向代理是为了保护服务器或负责负载均衡。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line"></span><br><span class="line">#1.创建处理器对象，在其内部封装代理ip和端口</span><br><span class="line">handler=urllib.request.ProxyHandler(proxies=&#123;&apos;http&apos;:&apos;95.172.58.224:52608&apos;&#125;)</span><br><span class="line">#2.创建opener对象，然后使用该对象发起一个请求</span><br><span class="line">opener=urllib.request.build_opener(handler)</span><br><span class="line"></span><br><span class="line">url=&apos;http://www.baidu.com/s?ie=UTF-8&amp;wd=ip&apos;</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36&apos;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url, headers=headers)</span><br><span class="line"></span><br><span class="line">#使用opener对象发起请求，该请求对应的ip即为我们设置的代理ip</span><br><span class="line">response = opener.open(request)</span><br><span class="line"></span><br><span class="line">with open(&apos;./daili.html&apos;,&apos;wb&apos;) as fp:</span><br><span class="line">    fp.write(response.read())</span><br></pre></td></tr></table></figure>
<blockquote>
<p> 2.cookie</p>
</blockquote>
<p>引言：有些时候，我们在使用爬虫程序去爬取一些用户相关信息的数据（爬取张三“人人网”个人主页数据）时，如果使用之前requests模块常规操作时，往往达不到我们想要的目的，例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">#指定url</span><br><span class="line">url = &apos;http://www.renren.com/289676607/profile&apos;</span><br><span class="line">#自定义请求头信息</span><br><span class="line">headers=&#123;</span><br><span class="line">    &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36&apos;,</span><br><span class="line">    &#125;</span><br><span class="line">#自定义请求对象</span><br><span class="line">request = urllib.request.Request(url=url,headers=headers)</span><br><span class="line">#发起请求</span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line">with open(&apos;./renren.html&apos;,&apos;w&apos;) as fp:</span><br><span class="line">    fp.write(response.read().decode())</span><br></pre></td></tr></table></figure>
<p>【注意】上述代码中，我们爬取到的是登录首页面，而不是张三的个人主页也面。why？首先我们来回顾下cookie的相关概念及作用</p>
<pre><code>- cookie概念：当用户通过浏览器首次访问一个域名时，访问的web服务器会给客户端发送数据，以保持web服务器与客户端之间的状态保持，这些数据就是cookie。

- cookie作用：我们在浏览器中，经常涉及到数据的交换，比如你登录邮箱，登录一个页面。我们经常会在此时设置30天内记住我，或者自动登录选项。那么它们是怎么记录信息的呢，答案就是今天的主角cookie了，Cookie是由HTTP服务器设置的，保存在浏览器中，但HTTP协议是一种无状态协议，在数据交换完毕后，服务器端和客户端的链接就会关闭，每次交换数据都需要建立新的链接。就像我们去超市买东西，没有积分卡的情况下，我们买完东西之后，超市没有我们的任何消费信息，但我们办了积分卡之后，超市就有了我们的消费信息。cookie就像是积分卡，可以保存积分，商品就是我们的信息，超市的系统就像服务器后台，http协议就是交易的过程。 

- 经过cookie的相关介绍，其实你已经知道了为什么上述案例中爬取到的不是张三个人信息页，而是登录页面。那应该如何抓取到张三的个人信息页呢？
</code></pre><p>　　思路：</p>
<p>　　　　1.我们需要使用爬虫程序对人人网的登录时的请求进行一次抓取，获取请求中的cookie数据</p>
<p>　　　　2.在使用个人信息页的url进行请求时，该请求需要携带 1 中的cookie，只有携带了cookie后，服务器才可识别这次请求的用户信息，方可响应回指定的用户信息页数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cookiejar对象：</span><br><span class="line">    - 作用：自动保存请求中的cookie数据信息</span><br><span class="line">    - 注意：必须和handler和opener一起使用</span><br><span class="line">cookiejar使用流程：</span><br><span class="line">    - 创建一个cookiejar对象</span><br><span class="line">      import http.cookiejar</span><br><span class="line">      cj = http.cookiejar.CookieJar()</span><br><span class="line">    - 通过cookiejar创建一个handler</span><br><span class="line">      handler = urllib.request.HTTPCookieProcessor(cj)</span><br><span class="line">    - 根据handler创建一个opener</span><br><span class="line">      opener = urllib.request.build_opener(handler)</span><br><span class="line">    - 使用opener.open方法去发送请求，且将响应中的cookie存储到openner对象中，后续的请求如果使用openner发起，则请求中就会携带了cookie</span><br></pre></td></tr></table></figure>
<p>使用cookiejar实现爬取人人网个人主页页面数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#使用cookiejar实现人人网的登陆</span><br><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">import http.cookiejar</span><br><span class="line">cj = http.cookiejar.CookieJar() #请求中的cookie会自动存储到cj对象中</span><br><span class="line">#创建处理器对象(携带cookiejar对象的)</span><br><span class="line">handler=urllib.request.HTTPCookieProcessor(cj)</span><br><span class="line">#创建opener对象 （携带cookiejar对象）</span><br><span class="line">opener=urllib.request.build_opener(handler)</span><br><span class="line"></span><br><span class="line">#要让cookiejar获取请求中的cookie数据值</span><br><span class="line">url=&apos;http://www.renren.com/ajaxLogin/login?1=1&amp;uniqueTimestamp=201873958471&apos;</span><br><span class="line">#自定义一个请求对象，让该对象作为opener的open函数中的参数</span><br><span class="line">data=&#123;</span><br><span class="line">    &quot;email&quot;:&quot;www.zhangbowudi@qq.com&quot;,</span><br><span class="line">    &quot;icode&quot;:&quot;&quot;,</span><br><span class="line">    &quot;origURL&quot;:&quot;http://www.renren.com/home&quot;,</span><br><span class="line">    &quot;domain&quot;:&quot;renren.com&quot;,</span><br><span class="line">    &quot;key_id&quot;:&quot;1&quot;,</span><br><span class="line">    &quot;captcha_type&quot;:&quot;web_login&quot;,</span><br><span class="line">    &quot;password&quot;:&quot;40dc65b82edd06d064b54a0fc6d202d8a58c4cb3d2942062f0f7dd128511fb9b&quot;,</span><br><span class="line">    &quot;rkey&quot;:&quot;41b44b0d062d3ca23119bc8b58983104&quot;,</span><br><span class="line">  </span><br><span class="line"> &apos;f&apos;:&quot;https%3A%2F%2Fwww.baidu.com%2Flink%3Furl%3DpPKf2680yRLbbZMVdntJpyPGwrSk2BtpKlEaAuKFTsW%26wd%3D%26eqid%3Deee20f380002988c000000025b7cbb80&quot;</span><br><span class="line">&#125;</span><br><span class="line">data=urllib.parse.urlencode(data).encode()</span><br><span class="line">request=urllib.request.Request(url,data=data)</span><br><span class="line">opener.open(request)</span><br><span class="line"></span><br><span class="line">#获取当前用户的二级子页面</span><br><span class="line">s_url=&apos;http://www.renren.com/289676607/profile&apos;</span><br><span class="line">#该次请求中就携带了cookie</span><br><span class="line">resonse=opener.open(s_url)</span><br><span class="line"></span><br><span class="line">with open(&apos;./renren.html&apos;,&apos;wb&apos;) as fp:</span><br><span class="line">    fp.write(resonse.read())</span><br></pre></td></tr></table></figure>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/M07/">M07</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="http://yoursite.com/2018/11/29/Py007-01-03内置urllib模块补充/" data-title="Py007-01-03内置urllib模块补充 | Almost" data-tsina="" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2018/11/29/Py007-01-04requests模块/" title="Py007-01-04requests模块">
  <strong>上一篇：</strong><br/>
  <span>
  Py007-01-04requests模块</span>
</a>
</div>


<div class="next">
<a href="/2018/11/29/Py007-01-02内置urllib模块/"  title="Py007-01-02内置urllib模块">
 <strong>下一篇：</strong><br/> 
 <span>Py007-01-02内置urllib模块
</span>
</a>
</div>

</nav>

	



</div>  
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">Contents</strong>
 
 <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#urllib补充"><span class="toc-number">1.</span> <span class="toc-text">urllib补充</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#二进制数据的爬取"><span class="toc-number">1.1.</span> <span class="toc-text">二进制数据的爬取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#url的特性"><span class="toc-number">1.2.</span> <span class="toc-text">url的特性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#通过自定义请求对象，用于伪装爬虫程序请求的身份。"><span class="toc-number">1.3.</span> <span class="toc-text">通过自定义请求对象，用于伪装爬虫程序请求的身份。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#携带参数的post请求"><span class="toc-number">1.4.</span> <span class="toc-text">携带参数的post请求</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#urllib模块的高级操作"><span class="toc-number">2.</span> <span class="toc-text">urllib模块的高级操作</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  


  

  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/oak/" title="oak">oak<sup>71</sup></a></li>
			
		
			
				<li><a href="/tags/前端知识点/" title="前端知识点">前端知识点<sup>43</sup></a></li>
			
		
			
				<li><a href="/tags/java/" title="java">java<sup>37</sup></a></li>
			
		
			
				<li><a href="/tags/Node后端/" title="Node后端">Node后端<sup>34</sup></a></li>
			
		
			
				<li><a href="/tags/M06/" title="M06">M06<sup>29</sup></a></li>
			
		
			
				<li><a href="/tags/fullstack/" title="fullstack">fullstack<sup>27</sup></a></li>
			
		
			
				<li><a href="/tags/M07/" title="M07">M07<sup>27</sup></a></li>
			
		
			
				<li><a href="/tags/python/" title="python">python<sup>26</sup></a></li>
			
		
			
				<li><a href="/tags/M08/" title="M08">M08<sup>25</sup></a></li>
			
		
			
				<li><a href="/tags/M04/" title="M04">M04<sup>22</sup></a></li>
			
		
			
				<li><a href="/tags/M03/" title="M03">M03<sup>20</sup></a></li>
			
		
			
				<li><a href="/tags/M02/" title="M02">M02<sup>17</sup></a></li>
			
		
			
				<li><a href="/tags/React入门/" title="React入门">React入门<sup>17</sup></a></li>
			
		
			
				<li><a href="/tags/ReactWheels/" title="ReactWheels">ReactWheels<sup>16</sup></a></li>
			
		
			
				<li><a href="/tags/TS入门/" title="TS入门">TS入门<sup>16</sup></a></li>
			
		
			
				<li><a href="/tags/M01/" title="M01">M01<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/vue/" title="vue">vue<sup>8</sup></a></li>
			
		
			
				<li><a href="/tags/ES6速学/" title="ES6速学">ES6速学<sup>7</sup></a></li>
			
		
			
				<li><a href="/tags/mongodb/" title="mongodb">mongodb<sup>7</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>7</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            
            	<a href="https://coderq.com" target="_blank" title="一个面向程序员交流分享的新一代社区">码农圈</a>
            
          </li>
        
          <li>
            
            	<a href="http://wuchong.me" target="_blank" title="Jark&#39;s Blog">Jark&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">Weibo</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=&verifier=b3593ceb&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Larry Page in Google. <br/>
			This is my blog,believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/2176287895" target="_blank" class="icon-weibo" title="微博"></a>
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2020 
		
		<a href="/about" target="_blank" title="Stevin">Stevin</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>











<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>
