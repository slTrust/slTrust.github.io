<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>Py007-01-03内置urllib模块补充 | Almost</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="urllib补充1234567891011121314# 补充说明：urlopen函数原型：    urllib.request.urlopen(url, data=None, timeout=&amp;lt;object object at 0x10af327d0&amp;gt;, *, cafile=None, capath=None, cadefault=False, context=None)在上一节中我">
<meta name="keywords" content="M07">
<meta property="og:type" content="article">
<meta property="og:title" content="Py007-01-03内置urllib模块补充">
<meta property="og:url" content="http://yoursite.com/2018/11/29/Py007-01-03内置urllib模块补充/index.html">
<meta property="og:site_name" content="Almost">
<meta property="og:description" content="urllib补充1234567891011121314# 补充说明：urlopen函数原型：    urllib.request.urlopen(url, data=None, timeout=&amp;lt;object object at 0x10af327d0&amp;gt;, *, cafile=None, capath=None, cadefault=False, context=None)在上一节中我">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2020-09-08T12:50:20.299Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Py007-01-03内置urllib模块补充">
<meta name="twitter:description" content="urllib补充1234567891011121314# 补充说明：urlopen函数原型：    urllib.request.urlopen(url, data=None, timeout=&amp;lt;object object at 0x10af327d0&amp;gt;, *, cafile=None, capath=None, cadefault=False, context=None)在上一节中我">
  
    <link rel="alternate" href="/atom.xml" title="Almost" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Almost</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Py007-01-03内置urllib模块补充" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/29/Py007-01-03内置urllib模块补充/" class="article-date">
  <time datetime="2018-11-29T14:59:14.000Z" itemprop="datePublished">2018-11-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Py007-01-03内置urllib模块补充
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="urllib补充"><a href="#urllib补充" class="headerlink" title="urllib补充"></a>urllib补充</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 补充说明：</span><br><span class="line">urlopen函数原型：</span><br><span class="line">    urllib.request.urlopen(url, data=None, timeout=&lt;object object at 0x10af327d0&gt;, *, cafile=None, capath=None, cadefault=False, context=None)</span><br><span class="line"></span><br><span class="line">在上一节中我们只使用了该函数中的第一个参数url。在日常开发中，我们能用的只有url和data这两个参数。</span><br><span class="line"></span><br><span class="line">url参数：指定向哪个url发起请求</span><br><span class="line">data参数：可以将post请求中携带的参数封装成字典的形式传递给该参数</span><br><span class="line"></span><br><span class="line">urlopen函数返回的响应对象，相关函数调用介绍：</span><br><span class="line">response.headers()：获取响应头信息</span><br><span class="line">response.getcode()：获取响应状态码</span><br><span class="line">response.geturl()：获取请求的url</span><br><span class="line">response.read()：获取响应中的数据值（字节类型）</span><br></pre></td></tr></table></figure>
<h4 id="二进制数据的爬取"><a href="#二进制数据的爬取" class="headerlink" title="二进制数据的爬取"></a>二进制数据的爬取</h4><blockquote>
<p>爬取网络上的某张图片数据，且存储到磁盘</p>
</blockquote>
<ul>
<li>方法 1：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line"></span><br><span class="line">#1.指定url</span><br><span class="line">url = &apos;https://pic.qiushibaike.com/system/pictures/12112/121121212/medium/ZOAND29U4NKNEWEF.jpg&apos;</span><br><span class="line">#2.发起请求:使用urlopen函数发起请求，该函数返回一个响应对象</span><br><span class="line">response = urllib.request.urlopen(url=url)</span><br><span class="line">#3.获取响应对象中的图片二进制类型的数据</span><br><span class="line">img_data = response.read()</span><br><span class="line">#4.持久化存储：将爬取的图片写入本地进行保存</span><br><span class="line">with open(&apos;./tupian.png&apos;,&apos;wb&apos;) as fp:</span><br><span class="line">    fp.write(img_data)</span><br></pre></td></tr></table></figure>
<ul>
<li>方法 2：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line"></span><br><span class="line">url = &apos;https://pic.qiushibaike.com/system/pictures/12112/121121212/medium/ZOAND29U4NKNEWEF.jpg&apos;</span><br><span class="line"># 函数原型：urllib.request.urlretrieve(url, filename=None)</span><br><span class="line"># 作用：对url发起请求，且将响应中的数据值写入磁盘进行存储</span><br><span class="line">urllib.request.urlretrieve(url=url,filename=&apos;./img.png&apos;)</span><br></pre></td></tr></table></figure>
<h4 id="url的特性"><a href="#url的特性" class="headerlink" title="url的特性"></a>url的特性</h4><p>url必须为ASCII编码的数据值。所以我们在爬虫代码中编写url时，如果url中存在非ASCII编码的数据值，则必须对其进行ASCII编码后，该url方可被使用。</p>
<blockquote>
<p>案例：爬取使用搜狗根据指定词条搜索到的页面数据（例如爬取词条为‘周杰伦’的页面数据）</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">url = &apos;https://www.sogou.com/web?query=周杰伦&apos;</span><br><span class="line">response = urllib.request.urlopen(url=url)</span><br><span class="line">data = response.read()</span><br><span class="line">with open(&apos;./周杰伦.html&apos;,&apos;wb&apos;) as fp:</span><br><span class="line">    fp.write(data)</span><br><span class="line">print(&apos;写入文件完毕&apos;)</span><br></pre></td></tr></table></figure>
<p>【注意】上述代码中url存在非ascii编码的数据，则该url无效。如果对其发起请求，则会报如下错误：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UnicodeEncodeError: &apos;ascii&apos; codec can&apos;t encode characters in position 15-17: ordinal not in range</span><br></pre></td></tr></table></figure>
<blockquote>
<p>所以必须对url中的非ascii的数据进行ascii的编码，则该url方可被发起请求：</p>
</blockquote>
<ul>
<li>方法 1：使用quote函数</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">url = &apos;https://www.sogou.com/web?query=%s&apos;</span><br><span class="line">#对url中的非ascii进行编码.quote函数可以对非ascii的数据值进行ascii的编码</span><br><span class="line">word = urllib.parse.quote(&apos;周杰伦&apos;)</span><br><span class="line">#将编码后的数据值拼接回url中</span><br><span class="line">url = format(url%word)</span><br><span class="line">response = urllib.request.urlopen(url=url)</span><br><span class="line">data = response.read()</span><br><span class="line">with open(&apos;./周杰伦.html&apos;,&apos;wb&apos;) as fp:</span><br><span class="line">    fp.write(data)</span><br><span class="line">print(&apos;写入文件完毕&apos;)</span><br></pre></td></tr></table></figure>
<ul>
<li>方法2： 使用urlencode函数</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">url = &apos;https://www.sogou.com/web?&apos;</span><br><span class="line">#将get请求中url携带的参数封装至字典中</span><br><span class="line">param = &#123;</span><br><span class="line">    &apos;query&apos;:&apos;周杰伦&apos;</span><br><span class="line">&#125;</span><br><span class="line">#对url中的非ascii进行编码</span><br><span class="line">param = urllib.parse.urlencode(param)</span><br><span class="line">#将编码后的数据值拼接回url中</span><br><span class="line">url += param </span><br><span class="line">response = urllib.request.urlopen(url=url)</span><br><span class="line">data = response.read()</span><br><span class="line">with open(&apos;./周杰伦1.html&apos;,&apos;wb&apos;) as fp:</span><br><span class="line">    fp.write(data)</span><br><span class="line">print(&apos;写入文件完毕&apos;)</span><br></pre></td></tr></table></figure>
<h4 id="通过自定义请求对象，用于伪装爬虫程序请求的身份。"><a href="#通过自定义请求对象，用于伪装爬虫程序请求的身份。" class="headerlink" title="通过自定义请求对象，用于伪装爬虫程序请求的身份。"></a>通过自定义请求对象，用于伪装爬虫程序请求的身份。</h4><p>之前在讲解http常用请求头信息时，我们讲解过User-Agent参数，简称为UA，该参数的作用是用于表明本次请求载体的身份标识。如果我们通过浏览器发起的请求，则该请求的载体为当前浏览器，则UA参数的值表明的是当前浏览器的身份标识表示的一串数据。如果我们使用爬虫程序发起的一个请求，则该请求的载体为爬虫程序，那么该请求的UA为爬虫程序的身份标识表示的一串数据。有些网站会通过辨别请求的UA来判别该请求的载体是否为爬虫程序，如果为爬虫程序，则不会给该请求返回响应，那么我们的爬虫程序则也无法通过请求爬取到该网站中的数据值，这也是反爬虫的一种初级技术手段。那么为了防止该问题的出现，则我们可以给爬虫程序的UA进行伪装，伪装成某款浏览器的身份标识。</p>
<p>上述案例中，我们是通过request模块中的urlopen发起的请求，该请求对象为urllib中内置的默认请求对象，我们无法对其进行UA进行更改操作。urllib还为我们提供了一种自定义请求对象的方式，我们可以通过自定义请求对象的方式，给该请求对象中的UA进行伪装（更改）操作。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">url = &apos;https://www.sogou.com/web?&apos;</span><br><span class="line">#将get请求中url携带的参数封装至字典中</span><br><span class="line">param = &#123;</span><br><span class="line">    &apos;query&apos;:&apos;周杰伦&apos;</span><br><span class="line">&#125;</span><br><span class="line">#对url中的非ascii进行编码</span><br><span class="line">param = urllib.parse.urlencode(param)</span><br><span class="line">#将编码后的数据值拼接回url中</span><br><span class="line">url += param </span><br><span class="line"></span><br><span class="line">#封装自定义的请求头信息的字典：</span><br><span class="line">#将浏览器的UA数据获取，封装到一个字典中。该UA值可以通过抓包工具或者浏览器自带的开发者工具中获取某请求，从中获取UA的值</span><br><span class="line">#注意：在headers字典中可以封装任意的请求头信息</span><br><span class="line">headers=&#123;</span><br><span class="line">    &apos;User-Agent&apos; : &apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36&apos;</span><br><span class="line">    &#125;</span><br><span class="line">#自定义请求对象，可以在该请求对象中添加自定义的请求头信息</span><br><span class="line">request = urllib.request.Request(url=url,headers=headers)</span><br><span class="line">#使用自定义请求对象发起请求</span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line">data = response.read()</span><br><span class="line">with open(&apos;./周杰伦.html&apos;,&apos;wb&apos;) as fp:</span><br><span class="line">    fp.write(data)</span><br><span class="line">print(&apos;写入文件完毕&apos;)</span><br></pre></td></tr></table></figure>
<h4 id="携带参数的post请求"><a href="#携带参数的post请求" class="headerlink" title="携带参数的post请求"></a>携带参数的post请求</h4><blockquote>
<p>案例：百度翻译发起post请求</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">#通过抓包工具抓取post请求的url</span><br><span class="line">post_url=&apos;https://fanyi.baidu.com/sug&apos;</span><br><span class="line">#封装post请求参数</span><br><span class="line">data=&#123;</span><br><span class="line">    &quot;kw&quot;:&quot;dog&quot;</span><br><span class="line">&#125;</span><br><span class="line">data=urllib.parse.urlencode(data)</span><br><span class="line">#自定义请求头信息字典</span><br><span class="line">headers=&#123;</span><br><span class="line">    &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#自定义请求对象，然后将封装好的post请求参数赋值给Requst方法的data参数。</span><br><span class="line">#data参数：用来存储post请求的参数</span><br><span class="line">request=urllib.request.Request(post_url,data=data.encode(),headers=headers)</span><br><span class="line">#自定义的请求对象中的参数（data必须为bytes类型）</span><br><span class="line">response=urllib.request.urlopen(request)</span><br><span class="line">response.read()</span><br></pre></td></tr></table></figure>
<h3 id="urllib模块的高级操作"><a href="#urllib模块的高级操作" class="headerlink" title="urllib模块的高级操作"></a>urllib模块的高级操作</h3><blockquote>
<ol>
<li>代理</li>
</ol>
</blockquote>
<ul>
<li><p>什么是代理：代理就是第三方代替本体处理相关事务。例如：生活中的代理：代购，中介，微商……</p>
</li>
<li><p>爬虫中为什么需要使用代理？</p>
<blockquote>
<p>一些网站会有相应的反爬虫措施，例如很多网站会检测某一段时间某个IP的访问次数，如果访问频率太快以至于看起来不像正常访客，它可能就会会禁止这个IP的访问。所以我们需要设置一些代理IP，每隔一段时间换一个代理IP，就算IP被禁止，依然可以换个IP继续爬取。</p>
</blockquote>
</li>
<li><p>代理的分类：</p>
</li>
</ul>
<p>正向代理：代理客户端获取数据。正向代理是为了保护客户端防止被追究责任。</p>
<p>反向代理：代理服务器提供数据。反向代理是为了保护服务器或负责负载均衡。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line"></span><br><span class="line">#1.创建处理器对象，在其内部封装代理ip和端口</span><br><span class="line">handler=urllib.request.ProxyHandler(proxies=&#123;&apos;http&apos;:&apos;95.172.58.224:52608&apos;&#125;)</span><br><span class="line">#2.创建opener对象，然后使用该对象发起一个请求</span><br><span class="line">opener=urllib.request.build_opener(handler)</span><br><span class="line"></span><br><span class="line">url=&apos;http://www.baidu.com/s?ie=UTF-8&amp;wd=ip&apos;</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36&apos;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url, headers=headers)</span><br><span class="line"></span><br><span class="line">#使用opener对象发起请求，该请求对应的ip即为我们设置的代理ip</span><br><span class="line">response = opener.open(request)</span><br><span class="line"></span><br><span class="line">with open(&apos;./daili.html&apos;,&apos;wb&apos;) as fp:</span><br><span class="line">    fp.write(response.read())</span><br></pre></td></tr></table></figure>
<blockquote>
<p> 2.cookie</p>
</blockquote>
<p>引言：有些时候，我们在使用爬虫程序去爬取一些用户相关信息的数据（爬取张三“人人网”个人主页数据）时，如果使用之前requests模块常规操作时，往往达不到我们想要的目的，例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">#指定url</span><br><span class="line">url = &apos;http://www.renren.com/289676607/profile&apos;</span><br><span class="line">#自定义请求头信息</span><br><span class="line">headers=&#123;</span><br><span class="line">    &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36&apos;,</span><br><span class="line">    &#125;</span><br><span class="line">#自定义请求对象</span><br><span class="line">request = urllib.request.Request(url=url,headers=headers)</span><br><span class="line">#发起请求</span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line">with open(&apos;./renren.html&apos;,&apos;w&apos;) as fp:</span><br><span class="line">    fp.write(response.read().decode())</span><br></pre></td></tr></table></figure>
<p>【注意】上述代码中，我们爬取到的是登录首页面，而不是张三的个人主页也面。why？首先我们来回顾下cookie的相关概念及作用</p>
<pre><code>- cookie概念：当用户通过浏览器首次访问一个域名时，访问的web服务器会给客户端发送数据，以保持web服务器与客户端之间的状态保持，这些数据就是cookie。

- cookie作用：我们在浏览器中，经常涉及到数据的交换，比如你登录邮箱，登录一个页面。我们经常会在此时设置30天内记住我，或者自动登录选项。那么它们是怎么记录信息的呢，答案就是今天的主角cookie了，Cookie是由HTTP服务器设置的，保存在浏览器中，但HTTP协议是一种无状态协议，在数据交换完毕后，服务器端和客户端的链接就会关闭，每次交换数据都需要建立新的链接。就像我们去超市买东西，没有积分卡的情况下，我们买完东西之后，超市没有我们的任何消费信息，但我们办了积分卡之后，超市就有了我们的消费信息。cookie就像是积分卡，可以保存积分，商品就是我们的信息，超市的系统就像服务器后台，http协议就是交易的过程。 

- 经过cookie的相关介绍，其实你已经知道了为什么上述案例中爬取到的不是张三个人信息页，而是登录页面。那应该如何抓取到张三的个人信息页呢？
</code></pre><p>　　思路：</p>
<p>　　　　1.我们需要使用爬虫程序对人人网的登录时的请求进行一次抓取，获取请求中的cookie数据</p>
<p>　　　　2.在使用个人信息页的url进行请求时，该请求需要携带 1 中的cookie，只有携带了cookie后，服务器才可识别这次请求的用户信息，方可响应回指定的用户信息页数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cookiejar对象：</span><br><span class="line">    - 作用：自动保存请求中的cookie数据信息</span><br><span class="line">    - 注意：必须和handler和opener一起使用</span><br><span class="line">cookiejar使用流程：</span><br><span class="line">    - 创建一个cookiejar对象</span><br><span class="line">      import http.cookiejar</span><br><span class="line">      cj = http.cookiejar.CookieJar()</span><br><span class="line">    - 通过cookiejar创建一个handler</span><br><span class="line">      handler = urllib.request.HTTPCookieProcessor(cj)</span><br><span class="line">    - 根据handler创建一个opener</span><br><span class="line">      opener = urllib.request.build_opener(handler)</span><br><span class="line">    - 使用opener.open方法去发送请求，且将响应中的cookie存储到openner对象中，后续的请求如果使用openner发起，则请求中就会携带了cookie</span><br></pre></td></tr></table></figure>
<p>使用cookiejar实现爬取人人网个人主页页面数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#使用cookiejar实现人人网的登陆</span><br><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">import http.cookiejar</span><br><span class="line">cj = http.cookiejar.CookieJar() #请求中的cookie会自动存储到cj对象中</span><br><span class="line">#创建处理器对象(携带cookiejar对象的)</span><br><span class="line">handler=urllib.request.HTTPCookieProcessor(cj)</span><br><span class="line">#创建opener对象 （携带cookiejar对象）</span><br><span class="line">opener=urllib.request.build_opener(handler)</span><br><span class="line"></span><br><span class="line">#要让cookiejar获取请求中的cookie数据值</span><br><span class="line">url=&apos;http://www.renren.com/ajaxLogin/login?1=1&amp;uniqueTimestamp=201873958471&apos;</span><br><span class="line">#自定义一个请求对象，让该对象作为opener的open函数中的参数</span><br><span class="line">data=&#123;</span><br><span class="line">    &quot;email&quot;:&quot;www.zhangbowudi@qq.com&quot;,</span><br><span class="line">    &quot;icode&quot;:&quot;&quot;,</span><br><span class="line">    &quot;origURL&quot;:&quot;http://www.renren.com/home&quot;,</span><br><span class="line">    &quot;domain&quot;:&quot;renren.com&quot;,</span><br><span class="line">    &quot;key_id&quot;:&quot;1&quot;,</span><br><span class="line">    &quot;captcha_type&quot;:&quot;web_login&quot;,</span><br><span class="line">    &quot;password&quot;:&quot;40dc65b82edd06d064b54a0fc6d202d8a58c4cb3d2942062f0f7dd128511fb9b&quot;,</span><br><span class="line">    &quot;rkey&quot;:&quot;41b44b0d062d3ca23119bc8b58983104&quot;,</span><br><span class="line">  </span><br><span class="line"> &apos;f&apos;:&quot;https%3A%2F%2Fwww.baidu.com%2Flink%3Furl%3DpPKf2680yRLbbZMVdntJpyPGwrSk2BtpKlEaAuKFTsW%26wd%3D%26eqid%3Deee20f380002988c000000025b7cbb80&quot;</span><br><span class="line">&#125;</span><br><span class="line">data=urllib.parse.urlencode(data).encode()</span><br><span class="line">request=urllib.request.Request(url,data=data)</span><br><span class="line">opener.open(request)</span><br><span class="line"></span><br><span class="line">#获取当前用户的二级子页面</span><br><span class="line">s_url=&apos;http://www.renren.com/289676607/profile&apos;</span><br><span class="line">#该次请求中就携带了cookie</span><br><span class="line">resonse=opener.open(s_url)</span><br><span class="line"></span><br><span class="line">with open(&apos;./renren.html&apos;,&apos;wb&apos;) as fp:</span><br><span class="line">    fp.write(resonse.read())</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/29/Py007-01-03内置urllib模块补充/" data-id="cknvgpu2o00je0xjpp4qvl3s5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/M07/">M07</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/11/29/Py007-01-04requests模块/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Py007-01-04requests模块
        
      </div>
    </a>
  
  
    <a href="/2018/11/29/Py007-01-02内置urllib模块/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Py007-01-02内置urllib模块</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CSS/">CSS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ES6速学/">ES6速学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JS不知深浅/">JS不知深浅</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M01/">M01</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M02/">M02</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M03/">M03</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M04/">M04</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M06/">M06</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M07/">M07</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M08/">M08</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M09/">M09</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NodeWeb/">NodeWeb</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Node后端/">Node后端</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ReactWheels/">ReactWheels</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/React入门/">React入门</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TS入门/">TS入门</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Webpack/">Webpack</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/express/">express</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/fullstack/">fullstack</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/http/">http</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jQuery/">jQuery</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mobile/">mobile</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mongodb/">mongodb</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/node/">node</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/node每日精进/">node每日精进</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/oak/">oak</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tools/">tools</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vim/">vim</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vue/">vue</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vultr/">vultr</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/web性能优化/">web性能优化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/web面经/">web面经</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/前端知识点/">前端知识点</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CSS/" style="font-size: 13.91px;">CSS</a> <a href="/tags/ES6速学/" style="font-size: 14.35px;">ES6速学</a> <a href="/tags/JS不知深浅/" style="font-size: 11.3px;">JS不知深浅</a> <a href="/tags/M01/" style="font-size: 13.48px;">M01</a> <a href="/tags/M02/" style="font-size: 15.22px;">M02</a> <a href="/tags/M03/" style="font-size: 15.65px;">M03</a> <a href="/tags/M04/" style="font-size: 16.09px;">M04</a> <a href="/tags/M06/" style="font-size: 18.26px;">M06</a> <a href="/tags/M07/" style="font-size: 17.83px;">M07</a> <a href="/tags/M08/" style="font-size: 16.96px;">M08</a> <a href="/tags/M09/" style="font-size: 11.74px;">M09</a> <a href="/tags/NodeWeb/" style="font-size: 15.65px;">NodeWeb</a> <a href="/tags/Node后端/" style="font-size: 18.7px;">Node后端</a> <a href="/tags/ReactWheels/" style="font-size: 16.52px;">ReactWheels</a> <a href="/tags/React入门/" style="font-size: 15.22px;">React入门</a> <a href="/tags/TS入门/" style="font-size: 14.78px;">TS入门</a> <a href="/tags/Webpack/" style="font-size: 11.3px;">Webpack</a> <a href="/tags/express/" style="font-size: 10.43px;">express</a> <a href="/tags/fullstack/" style="font-size: 17.83px;">fullstack</a> <a href="/tags/http/" style="font-size: 12.17px;">http</a> <a href="/tags/jQuery/" style="font-size: 10px;">jQuery</a> <a href="/tags/java/" style="font-size: 19.13px;">java</a> <a href="/tags/linux/" style="font-size: 10.87px;">linux</a> <a href="/tags/mobile/" style="font-size: 11.3px;">mobile</a> <a href="/tags/mongodb/" style="font-size: 12.61px;">mongodb</a> <a href="/tags/mysql/" style="font-size: 12.61px;">mysql</a> <a href="/tags/node/" style="font-size: 10.43px;">node</a> <a href="/tags/node每日精进/" style="font-size: 10px;">node每日精进</a> <a href="/tags/oak/" style="font-size: 20px;">oak</a> <a href="/tags/python/" style="font-size: 17.39px;">python</a> <a href="/tags/tools/" style="font-size: 10px;">tools</a> <a href="/tags/vim/" style="font-size: 10px;">vim</a> <a href="/tags/vue/" style="font-size: 13.04px;">vue</a> <a href="/tags/vultr/" style="font-size: 10px;">vultr</a> <a href="/tags/web性能优化/" style="font-size: 10px;">web性能优化</a> <a href="/tags/web面经/" style="font-size: 10px;">web面经</a> <a href="/tags/前端知识点/" style="font-size: 19.57px;">前端知识点</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">February 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">January 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">October 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/02/28/Webpack-03loader/">Webpack-03loader</a>
          </li>
        
          <li>
            <a href="/2021/02/27/Webpack-02打包器/">Webpack-02打包器</a>
          </li>
        
          <li>
            <a href="/2021/02/27/Webpack-01AST-Babel-依赖/">Webpack-01AST_Babel_依赖</a>
          </li>
        
          <li>
            <a href="/2021/02/26/Webpack-00前置内容理解webpack/">Webpack-00前置内容理解webpack</a>
          </li>
        
          <li>
            <a href="/2021/02/23/Node-web05-09-03博客系统使用nginx/">Node-web05-09-03博客系统使用nginx</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Stevin<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>