<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>Py007-02-05scrapy多个url爬取 | Almost</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="爬取多个页面url数据12# 糗事百科  文字标签页面的数据   它有13页https://www.qiushibaike.com/text/ 项目实战12345678910111213# 切换到桌面cd ~/Desktop # 创建项目scarpy startproject qiubaiByPages# 创建成功后进入该目录cd qiubaiByPages/# 创建spider 爬虫应用scra">
<meta name="keywords" content="M07">
<meta property="og:type" content="article">
<meta property="og:title" content="Py007-02-05scrapy多个url爬取">
<meta property="og:url" content="http://yoursite.com/2018/12/02/Py007-02-05scrapy多个url爬取/index.html">
<meta property="og:site_name" content="Almost">
<meta property="og:description" content="爬取多个页面url数据12# 糗事百科  文字标签页面的数据   它有13页https://www.qiushibaike.com/text/ 项目实战12345678910111213# 切换到桌面cd ~/Desktop # 创建项目scarpy startproject qiubaiByPages# 创建成功后进入该目录cd qiubaiByPages/# 创建spider 爬虫应用scra">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2020-09-08T12:50:20.302Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Py007-02-05scrapy多个url爬取">
<meta name="twitter:description" content="爬取多个页面url数据12# 糗事百科  文字标签页面的数据   它有13页https://www.qiushibaike.com/text/ 项目实战12345678910111213# 切换到桌面cd ~/Desktop # 创建项目scarpy startproject qiubaiByPages# 创建成功后进入该目录cd qiubaiByPages/# 创建spider 爬虫应用scra">
  
    <link rel="alternate" href="/atom.xml" title="Almost" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Almost</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Py007-02-05scrapy多个url爬取" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/02/Py007-02-05scrapy多个url爬取/" class="article-date">
  <time datetime="2018-12-02T05:51:40.000Z" itemprop="datePublished">2018-12-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Py007-02-05scrapy多个url爬取
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="爬取多个页面url数据"><a href="#爬取多个页面url数据" class="headerlink" title="爬取多个页面url数据"></a>爬取多个页面url数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 糗事百科  文字标签页面的数据   它有13页</span><br><span class="line">https://www.qiushibaike.com/text/</span><br></pre></td></tr></table></figure>
<h4 id="项目实战"><a href="#项目实战" class="headerlink" title="项目实战"></a>项目实战</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 切换到桌面</span><br><span class="line">cd ~/Desktop </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 创建项目</span><br><span class="line">scarpy startproject qiubaiByPages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 创建成功后进入该目录</span><br><span class="line">cd qiubaiByPages/</span><br><span class="line"></span><br><span class="line"># 创建spider 爬虫应用</span><br><span class="line">scrapy genspider qiubai www.qiushibaike.com/text</span><br></pre></td></tr></table></figure>
<blockquote>
<h4 id="第一步-修改spiders-qiubai-py"><a href="#第一步-修改spiders-qiubai-py" class="headerlink" title="第一步 修改spiders/qiubai.py"></a>第一步 修改spiders/qiubai.py</h4></blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line">class QiubaiSpider(scrapy.Spider):</span><br><span class="line">    name = &apos;qiubai&apos;</span><br><span class="line">    allowed_domains = [&apos;www.qiushibaike.com/text&apos;]</span><br><span class="line">    start_urls = [&apos;https://www.qiushibaike.com/text/&apos;]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        div_list = response.xpath(&apos;//*[@id=&quot;content-left&quot;]/div&apos;)</span><br><span class="line"></span><br><span class="line">        for div in div_list:</span><br><span class="line">            author = div.xpath(&apos;./div[@class=&quot;author clearfix&quot;]/a[2]/h2/text()&apos;).extract_first()</span><br><span class="line">            content = div.xpath(&apos;.//div[@class=&quot;content&quot;]/span/text()&apos;).extract_first()</span><br><span class="line"></span><br><span class="line">            # 创建items对象，将解析内容存储到items对象里</span><br><span class="line"></span><br><span class="line">        pass</span><br></pre></td></tr></table></figure>
<blockquote>
<h4 id="第二步-创建items对象-items-py"><a href="#第二步-创建items对象-items-py" class="headerlink" title="第二步 创建items对象  items.py"></a>第二步 创建items对象  items.py</h4></blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line">class QiubaibypagesItem(scrapy.Item):</span><br><span class="line">    author = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()</span><br></pre></td></tr></table></figure>
<blockquote>
<h4 id="第三步-在spiders-qiubai-py里导入items-并把item数据提交给管道文件"><a href="#第三步-在spiders-qiubai-py里导入items-并把item数据提交给管道文件" class="headerlink" title="第三步 在spiders/qiubai.py里导入items,并把item数据提交给管道文件"></a>第三步 在spiders/qiubai.py里导入items,并把item数据提交给管道文件</h4></blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">from qiubaiByPages.items import QiubaibypagesItem</span><br><span class="line"></span><br><span class="line">class QiubaiSpider(scrapy.Spider):</span><br><span class="line">    name = &apos;qiubai&apos;</span><br><span class="line">    # 建议注释掉 allowed_domains 图片的资源域名可能与此不一致</span><br><span class="line">    # allowed_domains = [&apos;www.qiushibaike.com/text&apos;]</span><br><span class="line">    start_urls = [&apos;https://www.qiushibaike.com/text/&apos;]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        div_list = response.xpath(&apos;//*[@id=&quot;content-left&quot;]/div&apos;)</span><br><span class="line"></span><br><span class="line">        for div in div_list:</span><br><span class="line">            author = div.xpath(&apos;./div[@class=&quot;author clearfix&quot;]/a[2]/h2/text()&apos;).extract_first()</span><br><span class="line">            content = div.xpath(&apos;.//div[@class=&quot;content&quot;]/span/text()&apos;).extract_first()</span><br><span class="line"></span><br><span class="line">            # 创建items对象，将解析内容存储到items对象里</span><br><span class="line">            item = QiubaibypagesItem()</span><br><span class="line">            item[&apos;author&apos;] = author</span><br><span class="line">            item[&apos;content&apos;] = content</span><br><span class="line"></span><br><span class="line">            # 将item对象提交给管道文件</span><br><span class="line">            yield item</span><br></pre></td></tr></table></figure>
<blockquote>
<p>修改管道文件pipelines.py</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">class QiubaibypagesPipeline(object):</span><br><span class="line">    fp = None</span><br><span class="line">    def open_spider(self,spider):</span><br><span class="line">        print(&apos;开始爬虫&apos;)</span><br><span class="line">        self.fp = open(&apos;./qiubai.txt&apos;,&apos;w&apos;,encoding=&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">    def close_spider(self,spider):</span><br><span class="line">        print(&apos;结束爬虫&apos;)</span><br><span class="line">        self.fp.close()</span><br><span class="line"></span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        self.fp.write(item[&apos;author&apos;]+&apos;:&apos;+item[&apos;content&apos;]+&apos;\n\n\n&apos;)</span><br><span class="line">        return item</span><br></pre></td></tr></table></figure>
<blockquote>
<h4 id="第四步-修改配置文件settings-py"><a href="#第四步-修改配置文件settings-py" class="headerlink" title="第四步 修改配置文件settings.py"></a>第四步 修改配置文件settings.py</h4></blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 伪装请求载体身份</span><br><span class="line">19行：USER_AGENT = &apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36&apos; </span><br><span class="line"></span><br><span class="line">22行：ROBOTSTXT_OBEY = False  #可以忽略或者不遵守robots协议</span><br><span class="line"># 不遵守robots协议</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 解开注释 管道操作配置</span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   &apos;qiubaiByPages.pipelines.QiubaibypagesPipeline&apos;: 300,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<h4 id="最后-回到刚刚的命令行-执行爬虫命令"><a href="#最后-回到刚刚的命令行-执行爬虫命令" class="headerlink" title="最后 回到刚刚的命令行 执行爬虫命令"></a>最后 回到刚刚的命令行 执行爬虫命令</h4></blockquote>
<p>把基础的流程跑通</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl qiubai --nolog</span><br></pre></td></tr></table></figure>
<h3 id="第二部分"><a href="#第二部分" class="headerlink" title="第二部分"></a>第二部分</h3><ul>
<li>上述流程跑通后，仅仅是一页的数据而</li>
<li>我们的需求是它的所有分页数据</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 该url的分页数据</span><br><span class="line">https://www.qiushibaike.com/text/</span><br></pre></td></tr></table></figure>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><ul>
<li>请求的手动发送</li>
</ul>
<blockquote>
<p>分析spiders/qiubai.py</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def parse(self, response):</span><br><span class="line">    ...</span><br><span class="line">    # 将item对象提交给管道文件</span><br><span class="line">    yield item</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">当yield item都执行完毕  意味着：</span><br><span class="line"></span><br><span class="line">https://www.qiushibaike.com/text/</span><br><span class="line">这一页面的数据爬取完毕</span><br><span class="line">&apos;&apos;&apos;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>手动处理下一次请求(仅仅以第二页数据为例)理解版本的parse函数修改</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def parse(self, response):</span><br><span class="line">    div_list = response.xpath(&apos;//*[@id=&quot;content-left&quot;]/div&apos;)</span><br><span class="line"></span><br><span class="line">    for div in div_list:</span><br><span class="line">        author = div.xpath(&apos;./div[@class=&quot;author clearfix&quot;]/a[2]/h2/text()&apos;).extract_first()</span><br><span class="line">        content = div.xpath(&apos;.//div[@class=&quot;content&quot;]/span/text()&apos;).extract_first()</span><br><span class="line"></span><br><span class="line">        # 创建items对象，将解析内容存储到items对象里</span><br><span class="line">        item = QiubaibypagesItem()</span><br><span class="line">        item[&apos;author&apos;] = author</span><br><span class="line">        item[&apos;content&apos;] = content</span><br><span class="line"></span><br><span class="line">        # 将item对象提交给管道文件</span><br><span class="line">        yield item</span><br><span class="line"></span><br><span class="line">    # 请求的手动发送</span><br><span class="line">    url = &apos;https://www.qiushibaike.com/text/page/2&apos;</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    url代表下一次请求的 url</span><br><span class="line">    callback代表将请求到的页面数据进行解析  而这个解析函数正是我们这里的parse函数</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    yield scrapy.Request(url=url,callback=self.parse)</span><br></pre></td></tr></table></figure>
<blockquote>
<h5 id="注意-这个版本-手动发送请求属于递归调用-由于没有结束条件所以会一直递归下去。。。。。"><a href="#注意-这个版本-手动发送请求属于递归调用-由于没有结束条件所以会一直递归下去。。。。。" class="headerlink" title="注意 这个版本 手动发送请求属于递归调用 由于没有结束条件所以会一直递归下去。。。。。"></a>注意 这个版本 手动发送请求属于递归调用 由于没有结束条件所以会一直递归下去。。。。。</h5></blockquote>
<blockquote>
<h5 id="注意-这个版本-手动发送请求属于递归调用-由于没有结束条件所以会一直递归下去。。。。。-1"><a href="#注意-这个版本-手动发送请求属于递归调用-由于没有结束条件所以会一直递归下去。。。。。-1" class="headerlink" title="注意 这个版本 手动发送请求属于递归调用 由于没有结束条件所以会一直递归下去。。。。。"></a>注意 这个版本 手动发送请求属于递归调用 由于没有结束条件所以会一直递归下去。。。。。</h5></blockquote>
<blockquote>
<h5 id="注意-这个版本-手动发送请求属于递归调用-由于没有结束条件所以会一直递归下去。。。。。-2"><a href="#注意-这个版本-手动发送请求属于递归调用-由于没有结束条件所以会一直递归下去。。。。。-2" class="headerlink" title="注意 这个版本 手动发送请求属于递归调用 由于没有结束条件所以会一直递归下去。。。。。"></a>注意 这个版本 手动发送请求属于递归调用 由于没有结束条件所以会一直递归下去。。。。。</h5></blockquote>
<blockquote>
<h4 id="完整版的qiubai-py文件"><a href="#完整版的qiubai-py文件" class="headerlink" title="完整版的qiubai.py文件"></a>完整版的qiubai.py文件</h4></blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">from qiubaiByPages.items import QiubaibypagesItem</span><br><span class="line"></span><br><span class="line">class QiubaiSpider(scrapy.Spider):</span><br><span class="line">    name = &apos;qiubai&apos;</span><br><span class="line">    # 注视掉这个 allowed_domains</span><br><span class="line">    # allowed_domains = [&apos;www.qiushibaike.com/text&apos;]</span><br><span class="line">    start_urls = [&apos;https://www.qiushibaike.com/text/&apos;]</span><br><span class="line"></span><br><span class="line">    # 设计通用的url模版</span><br><span class="line">    url = &apos;https://www.qiushibaike.com/text/page/%d&apos;</span><br><span class="line">    pageNum = 1</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        div_list = response.xpath(&apos;//*[@id=&quot;content-left&quot;]/div&apos;)</span><br><span class="line"></span><br><span class="line">        for div in div_list:</span><br><span class="line">            author = div.xpath(&apos;./div[@class=&quot;author clearfix&quot;]/a[2]/h2/text()&apos;).extract_first()</span><br><span class="line">            content = div.xpath(&apos;.//div[@class=&quot;content&quot;]/span/text()&apos;).extract_first()</span><br><span class="line"></span><br><span class="line">            # 创建items对象，将解析内容存储到items对象里</span><br><span class="line">            item = QiubaibypagesItem()</span><br><span class="line">            item[&apos;author&apos;] = author</span><br><span class="line">            item[&apos;content&apos;] = content</span><br><span class="line"></span><br><span class="line">            # 将item对象提交给管道文件</span><br><span class="line">            yield item</span><br><span class="line"></span><br><span class="line">        # 请求的手动发送</span><br><span class="line">        if self.pageNum &lt; 13: # 13表示是最后一页的页码</span><br><span class="line">            print(&apos;爬取到了第%d的页面数据&apos;%self.pageNum)</span><br><span class="line">            self.pageNum += 1 # 页码增加</span><br><span class="line">            new_url = format(self.url%self.pageNum)</span><br><span class="line">            yield scrapy.Request(url=new_url,callback=self.parse)</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/02/Py007-02-05scrapy多个url爬取/" data-id="ckkmr2k4z00ixfp91rql6gf65" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/M07/">M07</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/12/02/Py007-02-06scrapy核心组件/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Py007-02-06scrapy核心组件
        
      </div>
    </a>
  
  
    <a href="/2018/12/01/Py007-02-04scrapy管道高级操作/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Py007-02-04scrapy管道高级操作</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CSS/">CSS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ES6速学/">ES6速学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JS不知深浅/">JS不知深浅</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M01/">M01</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M02/">M02</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M03/">M03</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M04/">M04</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M06/">M06</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M07/">M07</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M08/">M08</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M09/">M09</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NodeWeb/">NodeWeb</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Node后端/">Node后端</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ReactWheels/">ReactWheels</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/React入门/">React入门</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TS入门/">TS入门</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/express/">express</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/fullstack/">fullstack</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/http/">http</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jQuery/">jQuery</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mobile/">mobile</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mongodb/">mongodb</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/node/">node</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/node每日精进/">node每日精进</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/oak/">oak</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tools/">tools</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vim/">vim</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vue/">vue</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vultr/">vultr</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/web性能优化/">web性能优化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/web面经/">web面经</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/前端知识点/">前端知识点</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CSS/" style="font-size: 14.09px;">CSS</a> <a href="/tags/ES6速学/" style="font-size: 13.64px;">ES6速学</a> <a href="/tags/JS不知深浅/" style="font-size: 11.36px;">JS不知深浅</a> <a href="/tags/M01/" style="font-size: 13.64px;">M01</a> <a href="/tags/M02/" style="font-size: 15px;">M02</a> <a href="/tags/M03/" style="font-size: 15.45px;">M03</a> <a href="/tags/M04/" style="font-size: 15.91px;">M04</a> <a href="/tags/M06/" style="font-size: 18.18px;">M06</a> <a href="/tags/M07/" style="font-size: 17.73px;">M07</a> <a href="/tags/M08/" style="font-size: 16.82px;">M08</a> <a href="/tags/M09/" style="font-size: 11.82px;">M09</a> <a href="/tags/NodeWeb/" style="font-size: 12.27px;">NodeWeb</a> <a href="/tags/Node后端/" style="font-size: 18.64px;">Node后端</a> <a href="/tags/ReactWheels/" style="font-size: 16.36px;">ReactWheels</a> <a href="/tags/React入门/" style="font-size: 15px;">React入门</a> <a href="/tags/TS入门/" style="font-size: 14.55px;">TS入门</a> <a href="/tags/express/" style="font-size: 10.45px;">express</a> <a href="/tags/fullstack/" style="font-size: 17.73px;">fullstack</a> <a href="/tags/http/" style="font-size: 12.27px;">http</a> <a href="/tags/jQuery/" style="font-size: 10px;">jQuery</a> <a href="/tags/java/" style="font-size: 19.09px;">java</a> <a href="/tags/linux/" style="font-size: 10.91px;">linux</a> <a href="/tags/mobile/" style="font-size: 11.36px;">mobile</a> <a href="/tags/mongodb/" style="font-size: 12.73px;">mongodb</a> <a href="/tags/mysql/" style="font-size: 12.73px;">mysql</a> <a href="/tags/node/" style="font-size: 10.45px;">node</a> <a href="/tags/node每日精进/" style="font-size: 10px;">node每日精进</a> <a href="/tags/oak/" style="font-size: 20px;">oak</a> <a href="/tags/python/" style="font-size: 17.27px;">python</a> <a href="/tags/tools/" style="font-size: 10px;">tools</a> <a href="/tags/vim/" style="font-size: 10px;">vim</a> <a href="/tags/vue/" style="font-size: 13.18px;">vue</a> <a href="/tags/vultr/" style="font-size: 10px;">vultr</a> <a href="/tags/web性能优化/" style="font-size: 10px;">web性能优化</a> <a href="/tags/web面经/" style="font-size: 10px;">web面经</a> <a href="/tags/前端知识点/" style="font-size: 19.55px;">前端知识点</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">January 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">October 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/01/20/HTTP06密码学到https流程/">HTTP06密码学到https流程</a>
          </li>
        
          <li>
            <a href="/2021/01/19/HTTP05缓存控制/">HTTP05缓存控制</a>
          </li>
        
          <li>
            <a href="/2021/01/18/HTTP04报文和http状态码/">HTTP04报文和http状态码</a>
          </li>
        
          <li>
            <a href="/2021/01/17/HTTP03http常用方法/">HTTP03http常用方法</a>
          </li>
        
          <li>
            <a href="/2021/01/16/HTTP02三次握手四度挥手/">HTTP02三次握手四度挥手</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Stevin<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>